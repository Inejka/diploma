{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Colab link: https://colab.research.google.com/drive/124fAI-rIGVkOHEi51ASkrbXnsenqWdaz?usp=sharing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: gradio in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (3.28.1)\n",
      "Requirement already satisfied: ffmpy in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: numpy in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (1.24.3)\n",
      "Requirement already satisfied: orjson in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (3.8.11)\n",
      "Requirement already satisfied: markupsafe in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (2.1.2)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: semantic-version in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (4.5.0)\n",
      "Requirement already satisfied: gradio-client>=0.1.3 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (0.1.4)\n",
      "Requirement already satisfied: matplotlib in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: requests in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (2.29.0)\n",
      "Requirement already satisfied: aiohttp in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (3.8.4)\n",
      "Requirement already satisfied: jinja2 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: httpx in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (0.24.0)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (0.3.3)\n",
      "Requirement already satisfied: uvicorn in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (0.22.0)\n",
      "Requirement already satisfied: pillow in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (9.5.0)\n",
      "Requirement already satisfied: python-multipart in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: aiofiles in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (23.1.0)\n",
      "Requirement already satisfied: pyyaml in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: pydantic in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (1.10.7)\n",
      "Requirement already satisfied: fastapi in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (0.95.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (0.14.1)\n",
      "Requirement already satisfied: pydub in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: altair>=4.2.0 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (4.2.2)\n",
      "Requirement already satisfied: websockets>=10.0 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (11.0.2)\n",
      "Requirement already satisfied: pandas in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio) (2.0.1)\n",
      "Requirement already satisfied: entrypoints in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from altair>=4.2.0->gradio) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from altair>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: fsspec in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio-client>=0.1.3->gradio) (2023.4.0)\n",
      "Requirement already satisfied: packaging in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from gradio-client>=0.1.3->gradio) (23.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from huggingface-hub>=0.13.0->gradio) (4.65.0)\n",
      "Requirement already satisfied: filelock in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from huggingface-hub>=0.13.0->gradio) (3.12.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from pandas->gradio) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from pandas->gradio) (2023.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from aiohttp->gradio) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from aiohttp->gradio) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from aiohttp->gradio) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from aiohttp->gradio) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from aiohttp->gradio) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from aiohttp->gradio) (3.1.0)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from fastapi->gradio) (0.26.1)\n",
      "Requirement already satisfied: sniffio in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from httpx->gradio) (0.17.0)\n",
      "Requirement already satisfied: idna in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from httpx->gradio) (3.4)\n",
      "Requirement already satisfied: certifi in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from httpx->gradio) (2022.12.7)\n",
      "Requirement already satisfied: cycler>=0.10 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from matplotlib->gradio) (4.39.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from matplotlib->gradio) (1.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from requests->gradio) (1.26.15)\n",
      "Requirement already satisfied: click>=7.0 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from uvicorn->gradio) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from uvicorn->gradio) (0.14.0)\n",
      "Requirement already satisfied: colorama in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from click>=7.0->uvicorn->gradio) (0.4.6)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
      "Requirement already satisfied: uc-micro-py in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in i:\\pycharmprojects\\diploma\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->gradio) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: I:\\PycharmProjects\\Diploma\\venv\\Scripts\\python.exe -m pip install --upgrade pip\n",
      "\"rm\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "%pip install gradio\n",
    "!rm /content/sample_data -rf\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "if not os.path.exists(\"/content/drive/MyDrive/image_scorer\"):\n",
    "    os.mkdir(\"/content/drive/MyDrive/image_scorer\")\n",
    "if not os.path.exists(\"/content/drive/MyDrive/image_scorer/flagged\"):\n",
    "  os.mkdir(\"/content/drive/MyDrive/image_scorer/flagged\")\n",
    "!ln -s /content/drive/MyDrive/image_scorer/flagged /content/flagged"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:48:01.599371Z",
     "start_time": "2023-05-04T14:47:55.441273100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import logging\n",
    "import sqlite3\n",
    "\n",
    "import gdown\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet101, ResNet101_Weights\n",
    "from PIL import ImageFile\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "\n",
    "class CollectionsDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 csv_file,\n",
    "                 root_dir,\n",
    "                 num_classes,\n",
    "                 transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.data.loc[idx, 'image_path'])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label_tensor = torch.zeros(self.num_classes)\n",
    "        label_tensor[self.data.loc[idx, 'rating'] - 1] = 1\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return {'image': image,\n",
    "                'labels': label_tensor\n",
    "                }\n",
    "\n",
    "\n",
    "def train_model(model,\n",
    "                data_loader,\n",
    "                dataset_size,\n",
    "                optimizer,\n",
    "                scheduler,\n",
    "                num_epochs):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        logging.info('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        logging.info('-' * 10)\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        # Iterate over data.\n",
    "        for bi, d in enumerate(data_loader):\n",
    "            inputs = d[\"image\"]\n",
    "            labels = d[\"labels\"]\n",
    "            inputs = inputs.to(device, dtype=torch.float)\n",
    "            labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        scheduler.step()\n",
    "        logging.info('Loss: {:.4f}'.format(epoch_loss))\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_from_resnet101_with_dataset():\n",
    "    model = get_model_definition()\n",
    "\n",
    "    # define some re-usable stuff\n",
    "    IMAGE_SIZE = 512\n",
    "    BATCH_SIZE = 9\n",
    "    IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "    IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "    # make some augmentations on training data\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.CenterCrop(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(IMG_MEAN, IMG_STD)\n",
    "    ])\n",
    "\n",
    "    # use the collections dataset class we created earlier\n",
    "    CSV_FILE_TRAIN = r\"dataset\\balanced\\data.csv\"\n",
    "    ROOT_DIR_TRAIN = r\"dataset\\balanced\"\n",
    "\n",
    "    train_dataset = CollectionsDataset(CSV_FILE_TRAIN, ROOT_DIR_TRAIN, NUM_CLASSES, train_transform)\n",
    "\n",
    "    # create the pytorch data loader\n",
    "    train_dataset_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                       batch_size=BATCH_SIZE,\n",
    "                                                       shuffle=True)\n",
    "    # push model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    plist = [\n",
    "        {'params': model.layer4.parameters(), 'lr': 1e-5},\n",
    "        {'params': model.fc.parameters(), 'lr': 5e-3}\n",
    "    ]\n",
    "    optimizer_ft = optim.Adam(plist, lr=0.001)\n",
    "    lr_sch = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "\n",
    "    model = train_model(model,\n",
    "                        train_dataset_loader,\n",
    "                        len(train_dataset),\n",
    "                        optimizer_ft,\n",
    "                        lr_sch,\n",
    "                        num_epochs=5)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model_from_ram_with_flagged(model, transforms, num_epochs=5, batch_size=9, lrs=[1e-5, 5e-3, 1e-3]):\n",
    "    sql_to_csv()\n",
    "    CSV_FILE_TRAIN = os.path.join(\"flagged\", \"data.csv\")\n",
    "    ROOT_DIR_TRAIN = \"\"\n",
    "    train_dataset = CollectionsDataset(CSV_FILE_TRAIN, ROOT_DIR_TRAIN, NUM_CLASSES, transforms)\n",
    "    train_dataset_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       shuffle=True)\n",
    "\n",
    "    plist = [\n",
    "        {'params': model.layer4.parameters(), 'lr': lrs[0]},\n",
    "        {'params': model.fc.parameters(), 'lr': lrs[1]}\n",
    "    ]\n",
    "    optimizer_ft = optim.Adam(plist, lr=lrs[2])\n",
    "    lr_sch = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "\n",
    "    model = train_model(model,\n",
    "                        train_dataset_loader,\n",
    "                        len(train_dataset),\n",
    "                        optimizer_ft,\n",
    "                        lr_sch,\n",
    "                        num_epochs=num_epochs)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model_from_my_pretrained(transforms, num_epochs=5, batch_size=9, lrs=[1e-5, 5e-3, 1e-3]):\n",
    "    if not os.path.exists(\"model_pretrained.bin\"):\n",
    "        logging.info(\"Missing model, downloading\")\n",
    "        url = 'https://drive.google.com/uc?id=1uyIYjcPRg6TwIrLpa_p9bmCALtAax79F'\n",
    "        output = 'model_pretrained.bin'\n",
    "        gdown.download(url, output, quiet=False)\n",
    "        logging.info(\"Model downloaded\")\n",
    "    model = get_model_definition()\n",
    "    model.load_state_dict(torch.load(\"model_pretrained.bin\"))\n",
    "    model = model.to(device)\n",
    "    sql_to_csv()\n",
    "    CSV_FILE_TRAIN = os.path.join(\"flagged\", \"data.csv\")\n",
    "    ROOT_DIR_TRAIN = \"\"\n",
    "    train_dataset = CollectionsDataset(CSV_FILE_TRAIN, ROOT_DIR_TRAIN, NUM_CLASSES, transforms)\n",
    "    train_dataset_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       shuffle=True)\n",
    "\n",
    "    plist = [\n",
    "        {'params': model.layer4.parameters(), 'lr': lrs[0]},\n",
    "        {'params': model.fc.parameters(), 'lr': lrs[1]}\n",
    "    ]\n",
    "    optimizer_ft = optim.Adam(plist, lr=lrs[2])\n",
    "    lr_sch = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "\n",
    "    model = train_model(model,\n",
    "                        train_dataset_loader,\n",
    "                        len(train_dataset),\n",
    "                        optimizer_ft,\n",
    "                        lr_sch,\n",
    "                        num_epochs=num_epochs)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model_definition():\n",
    "    model = resnet101(weights=ResNet101_Weights.IMAGENET1K_V2)\n",
    "    model.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.BatchNorm1d(2048),\n",
    "        nn.Dropout(p=0.25),\n",
    "        nn.Linear(in_features=2048, out_features=2048),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(in_features=2048, out_features=10),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def sql_to_csv():\n",
    "    conn = sqlite3.connect(os.path.join(\"flagged\", \"data.db\"), isolation_level=None,\n",
    "                           detect_types=sqlite3.PARSE_COLNAMES)\n",
    "    db_df = pd.read_sql_query(\"SELECT * FROM images\", conn)\n",
    "    db_df.to_csv(os.path.join(\"flagged\", \"data.csv\"), index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:48:01.599874800Z",
     "start_time": "2023-05-04T14:48:01.575372Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://71dcaca8d012ad4b06.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div><iframe src=\"https://71dcaca8d012ad4b06.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import logging\n",
    "from collections import UserDict\n",
    "from io import BytesIO\n",
    "\n",
    "import gradio as gr\n",
    "import requests\n",
    "\n",
    "# ENABLE LOGGING--------------------------------------------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"debug.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ],\n",
    "    force=True\n",
    ")\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# CREATE DATABASE------------------------------------------------------------------------------------------------------\n",
    "if not os.path.exists(\"flagged\"):\n",
    "    os.mkdir(\"flagged\")\n",
    "conn = sqlite3.connect(os.path.join(\"flagged\", \"data.db\"))\n",
    "c = conn.cursor()\n",
    "c.execute(''' SELECT count(name) FROM sqlite_master WHERE type='table' AND name='images' ''')\n",
    "if not c.fetchone()[0] == 1:\n",
    "    c.execute('''CREATE TABLE images\n",
    "             (id SERIAL PRIMARY KEY, image_path TEXT, rating INTEGER)''')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# dowlonad model if it is missing----------------------------------------------------------------------------------------\n",
    "\n",
    "if not os.path.exists(\"model.bin\"):\n",
    "    logging.info(\"Missing model, downloading\")\n",
    "    url = 'https://drive.google.com/uc?id=1uyIYjcPRg6TwIrLpa_p9bmCALtAax79F'\n",
    "    output = 'model.bin'\n",
    "    gdown.download(url, output, quiet=False)\n",
    "    logging.info(\"Model downloaded\")\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# DEFINE MODEl----------------------------------------------------------------------------------------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = get_model_definition()\n",
    "model.load_state_dict(torch.load(\"model.bin\"))\n",
    "\n",
    "IMAGE_SIZE = 512\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "my_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMG_MEAN, IMG_STD)\n",
    "])\n",
    "model = model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# CREATE AND DIFINE BUFFE-----------------------------------------------------------------------------------------------\n",
    "class Buffer(UserDict):\n",
    "    def __init__(self, max_size=10, *args, **kwargs):\n",
    "        self.max_size = max_size\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        if len(self) >= self.max_size:\n",
    "            oldest_key = next(iter(self))\n",
    "            del self[oldest_key]\n",
    "        super().__setitem__(key, value)\n",
    "\n",
    "\n",
    "buffer = Buffer(1000)\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"}\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"Image scorer backend.\")\n",
    "    with gr.Tab(\"I am here for api only, pls don't touch me\", visible=True):\n",
    "        # this is for image adding for database\n",
    "        img_input = gr.Textbox()\n",
    "        score_input = gr.Textbox()\n",
    "        button = gr.Button('Click me!')\n",
    "\n",
    "\n",
    "        def add_image(inp, score=None):\n",
    "            logging.info(f\"Got image with src {inp} and score {score}\")\n",
    "            conn = sqlite3.connect(os.path.join(\"flagged\", \"data.db\"))\n",
    "            c = conn.cursor()\n",
    "            c.execute(\"SELECT COUNT(*) FROM images\")\n",
    "\n",
    "            # Fetch the result of the query\n",
    "            row_count = c.fetchone()[0]\n",
    "\n",
    "            req = requests.get(inp, headers=headers)\n",
    "            img = Image.open(BytesIO(req.content))\n",
    "            img.save(os.path.join(\"flagged\", str(row_count) + \".png\"))\n",
    "            c.execute(\"INSERT INTO images (image_path, rating) VALUES (?, ?)\",\n",
    "                      (os.path.join(\"flagged\", str(row_count) + \".png\"), score))\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            logging.info(\"Image added\")\n",
    "            return \"readed\"\n",
    "\n",
    "\n",
    "        button.click(add_image, inputs=[img_input, score_input])\n",
    "\n",
    "        # this is for connection test\n",
    "        txt_output = gr.Textbox()\n",
    "        button = gr.Button('Connection test')\n",
    "\n",
    "\n",
    "        def return_ok():\n",
    "            logging.info(\"Connected\")\n",
    "            return \"connected\"\n",
    "\n",
    "\n",
    "        button.click(return_ok, outputs=txt_output)\n",
    "\n",
    "        # this is for model predict\n",
    "        img_input_predict = gr.Textbox()\n",
    "        score_output = gr.Textbox()\n",
    "        button = gr.Button('Predict')\n",
    "\n",
    "\n",
    "        def predict(inp):\n",
    "            if not str(inp):\n",
    "                logging.info(\"Got empty string, returning -1\")\n",
    "                return \"-1\"\n",
    "            if inp in buffer:\n",
    "                logging.info(f\"Using buffer, returned {buffer[inp]}\")\n",
    "                return buffer[inp]\n",
    "            try:\n",
    "                logging.info(f\"Got: {inp}\")\n",
    "                if str(inp).find(\"http\") != -1:\n",
    "                    logging.info(\"Requesting image\")\n",
    "                    req = requests.get(inp, headers=headers)\n",
    "                    logging.info(\"Got image\")\n",
    "                    img = Image.open(BytesIO(req.content)).convert('RGB')\n",
    "                if str(inp).find(\"base64\") != -1:\n",
    "                    logging.info(\"Got base64, decoding\")\n",
    "                    image_bytes = base64.b64decode(inp.split(',')[1])\n",
    "                    img = Image.open(BytesIO(image_bytes)).convert('RGB')\n",
    "                logging.info(\"Transforming image\")\n",
    "                img = my_transforms(img).to(device).unsqueeze(0)\n",
    "                logging.info(\"Predicting\")\n",
    "                ans = str(torch.argmax(model(img).sigmoid()).item() + 1)\n",
    "                logging.info(f\"Responsed with: {ans}\")\n",
    "                buffer[inp] = ans\n",
    "                torch.cuda.empty_cache()\n",
    "                return ans\n",
    "            except Exception:\n",
    "                logging.error(\"Error: \" + str(Exception), exc_info=True)\n",
    "                logging.error(f\"Response status was {req.status_code}\")\n",
    "                return \"-1\"\n",
    "\n",
    "\n",
    "        button.click(predict, inputs=img_input_predict, outputs=score_output)\n",
    "\n",
    "    with gr.Tab(\"Train tab\", visible=True):\n",
    "        with gr.Row():\n",
    "            epochs = gr.Number(value=10, label=\"Epochs\", interactive=True)\n",
    "            batch_size = gr.Number(value=9, label=\"Batch size\", interactive=True)\n",
    "        with gr.Row():\n",
    "            l4lr = gr.Number(value=1e-5, label=\"layer4.parameter LR\", interactive=True)\n",
    "            fclr = gr.Number(value=5e-3, label=\"fc.parameter LR\", interactive=True)\n",
    "            adamLR = gr.Number(value=1e-3, label=\"adam LR\", interactive=True)\n",
    "        button = gr.Button('Train model from ram')\n",
    "\n",
    "\n",
    "        def standart_eval_prep():\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            model.eval()\n",
    "            torch.cuda.empty_cache()\n",
    "            buffer.clear()\n",
    "\n",
    "\n",
    "        def train_with_flagged(lr1, lr2, lr3, batch_size_pm, epochs_pm):\n",
    "            try:\n",
    "                logging.info(\"Starting training\")\n",
    "                global model\n",
    "                model = train_model_from_ram_with_flagged(model, my_transforms, int(epochs_pm), int(batch_size_pm),\n",
    "                                                          lrs=[lr1, lr2, lr3])\n",
    "                standart_eval_prep()\n",
    "                logging.info(\"Training finished\")\n",
    "            except:\n",
    "                logging.error(str(Exception), exc_info=True)\n",
    "                standart_eval_prep()\n",
    "\n",
    "\n",
    "        button.click(train_with_flagged, inputs=[l4lr, fclr, adamLR, batch_size, epochs])\n",
    "\n",
    "        button = gr.Button('Train model from pretrained')\n",
    "\n",
    "\n",
    "        def train_from_pretrained(lr1, lr2, lr3, batch_size_pm, epochs_pm):\n",
    "            try:\n",
    "                logging.info(\"Starting training\")\n",
    "                global model\n",
    "                model = train_model_from_my_pretrained(my_transforms, int(epochs_pm), int(batch_size_pm),\n",
    "                                                       lrs=[lr1, lr2, lr3])\n",
    "                standart_eval_prep()\n",
    "                logging.info(\"Training finished\")\n",
    "            except Exception:\n",
    "                logging.error(str(Exception), exc_info=True)\n",
    "                standart_eval_prep()\n",
    "\n",
    "\n",
    "        button.click(train_from_pretrained, inputs=[l4lr, fclr, adamLR, batch_size, epochs])\n",
    "\n",
    "        button = gr.Button(\"Load standart pretrained\")\n",
    "\n",
    "\n",
    "        def load_standart_pretrained():\n",
    "            logging.info(\"Loading model\")\n",
    "            global model\n",
    "            model.load_state_dict(torch.load(\"model.bin\"))\n",
    "            standart_eval_prep()\n",
    "            logging.info(\"Model loaded\")\n",
    "\n",
    "\n",
    "        button.click(load_standart_pretrained)\n",
    "\n",
    "app.queue(concurrency_count=1, max_size=60)\n",
    "app.launch(max_threads=1, share=True)\n",
    "\n",
    "while True:\n",
    "    pass\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:48:13.247052600Z",
     "start_time": "2023-05-04T14:48:01.603372Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
