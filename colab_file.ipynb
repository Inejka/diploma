{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pip install gradio\n",
    "!rm /content/sample_data -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import logging\n",
    "import sqlite3\n",
    "\n",
    "import gdown\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet101, ResNet101_Weights\n",
    "from PIL import ImageFile\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "\n",
    "class CollectionsDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 csv_file,\n",
    "                 root_dir,\n",
    "                 num_classes,\n",
    "                 transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.data.loc[idx, 'image_path'])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label_tensor = torch.zeros(self.num_classes)\n",
    "        label_tensor[self.data.loc[idx, 'rating'] - 1] = 1\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return {'image': image,\n",
    "                'labels': label_tensor\n",
    "                }\n",
    "\n",
    "\n",
    "def train_model(model,\n",
    "                data_loader,\n",
    "                dataset_size,\n",
    "                optimizer,\n",
    "                scheduler,\n",
    "                num_epochs):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        logging.info('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        logging.info('-' * 10)\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        # Iterate over data.\n",
    "        for bi, d in enumerate(data_loader):\n",
    "            inputs = d[\"image\"]\n",
    "            labels = d[\"labels\"]\n",
    "            inputs = inputs.to(device, dtype=torch.float)\n",
    "            labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        scheduler.step()\n",
    "        logging.info('Loss: {:.4f}'.format(epoch_loss))\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_from_resnet101_with_dataset():\n",
    "    model = get_model_definition()\n",
    "\n",
    "    # define some re-usable stuff\n",
    "    IMAGE_SIZE = 512\n",
    "    BATCH_SIZE = 9\n",
    "    IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "    IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "    # make some augmentations on training data\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.CenterCrop(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(IMG_MEAN, IMG_STD)\n",
    "    ])\n",
    "\n",
    "    # use the collections dataset class we created earlier\n",
    "    CSV_FILE_TRAIN = r\"dataset\\balanced\\data.csv\"\n",
    "    ROOT_DIR_TRAIN = r\"dataset\\balanced\"\n",
    "\n",
    "    train_dataset = CollectionsDataset(CSV_FILE_TRAIN, ROOT_DIR_TRAIN, NUM_CLASSES, train_transform)\n",
    "\n",
    "    # create the pytorch data loader\n",
    "    train_dataset_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                       batch_size=BATCH_SIZE,\n",
    "                                                       shuffle=True)\n",
    "    # push model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    plist = [\n",
    "        {'params': model.layer4.parameters(), 'lr': 1e-5},\n",
    "        {'params': model.fc.parameters(), 'lr': 5e-3}\n",
    "    ]\n",
    "    optimizer_ft = optim.Adam(plist, lr=0.001)\n",
    "    lr_sch = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "\n",
    "    model = train_model(model,\n",
    "                        train_dataset_loader,\n",
    "                        len(train_dataset),\n",
    "                        optimizer_ft,\n",
    "                        lr_sch,\n",
    "                        num_epochs=5)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model_from_ram_with_flagged(model, transforms, num_epochs=5, batch_size=9):\n",
    "    sql_to_csv()\n",
    "    CSV_FILE_TRAIN = os.path.join(\"flagged\", \"data.csv\")\n",
    "    ROOT_DIR_TRAIN = \"\"\n",
    "    train_dataset = CollectionsDataset(CSV_FILE_TRAIN, ROOT_DIR_TRAIN, NUM_CLASSES, transforms)\n",
    "    train_dataset_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       shuffle=True)\n",
    "\n",
    "    plist = [\n",
    "        {'params': model.layer4.parameters(), 'lr': 1e-6},\n",
    "        {'params': model.fc.parameters(), 'lr': 5e-4}\n",
    "    ]\n",
    "    optimizer_ft = optim.Adam(plist, lr=0.0001)\n",
    "    lr_sch = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "\n",
    "    model = train_model(model,\n",
    "                        train_dataset_loader,\n",
    "                        len(train_dataset),\n",
    "                        optimizer_ft,\n",
    "                        lr_sch,\n",
    "                        num_epochs=num_epochs)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model_from_my_pretrained(transforms, num_epochs=5, batch_size=9):\n",
    "    if not os.path.exists(\"model_pretrained.bin\"):\n",
    "        logging.info(\"Missing model, downloading\")\n",
    "        url = 'https://drive.google.com/uc?id=1uyIYjcPRg6TwIrLpa_p9bmCALtAax79F'\n",
    "        output = 'model_pretrained.bin'\n",
    "        gdown.download(url, output, quiet=False)\n",
    "        logging.info(\"Model downloaded\")\n",
    "    model = get_model_definition()\n",
    "    model.load_state_dict(torch.load(\"model_pretrained.bin\"))\n",
    "    model = model.to(device)\n",
    "    sql_to_csv()\n",
    "    CSV_FILE_TRAIN = os.path.join(\"flagged\", \"data.csv\")\n",
    "    ROOT_DIR_TRAIN = \"\"\n",
    "    train_dataset = CollectionsDataset(CSV_FILE_TRAIN, ROOT_DIR_TRAIN, NUM_CLASSES, transforms)\n",
    "    train_dataset_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       shuffle=True)\n",
    "\n",
    "    plist = [\n",
    "        {'params': model.layer4.parameters(), 'lr': 1e-6},\n",
    "        {'params': model.fc.parameters(), 'lr': 5e-4}\n",
    "    ]\n",
    "    optimizer_ft = optim.Adam(plist, lr=0.0001)\n",
    "    lr_sch = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "\n",
    "    model = train_model(model,\n",
    "                        train_dataset_loader,\n",
    "                        len(train_dataset),\n",
    "                        optimizer_ft,\n",
    "                        lr_sch,\n",
    "                        num_epochs=num_epochs)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model_definition():\n",
    "    model = resnet101(weights=ResNet101_Weights.IMAGENET1K_V2)\n",
    "    model.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.BatchNorm1d(2048),\n",
    "        nn.Dropout(p=0.25),\n",
    "        nn.Linear(in_features=2048, out_features=2048),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(in_features=2048, out_features=10),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def sql_to_csv():\n",
    "    conn = sqlite3.connect(os.path.join(\"flagged\", \"data.db\"), isolation_level=None,\n",
    "                           detect_types=sqlite3.PARSE_COLNAMES)\n",
    "    db_df = pd.read_sql_query(\"SELECT * FROM images\", conn)\n",
    "    db_df.to_csv(os.path.join(\"flagged\", \"data.csv\"), index=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import base64\n",
    "from collections import UserDict\n",
    "from io import BytesIO\n",
    "\n",
    "import gradio as gr\n",
    "import requests\n",
    "\n",
    "\n",
    "# ENABLE LOGGING--------------------------------------------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"debug.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ],\n",
    "    force=True\n",
    ")\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# CREATE DATABASE------------------------------------------------------------------------------------------------------\n",
    "if not os.path.exists(\"flagged\"):\n",
    "    os.mkdir(\"flagged\")\n",
    "conn = sqlite3.connect(os.path.join(\"flagged\", \"data.db\"))\n",
    "c = conn.cursor()\n",
    "c.execute(''' SELECT count(name) FROM sqlite_master WHERE type='table' AND name='images' ''')\n",
    "if not c.fetchone()[0] == 1:\n",
    "    c.execute('''CREATE TABLE images\n",
    "             (id SERIAL PRIMARY KEY, image_path TEXT, rating INTEGER)''')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# dowlonad model if it is missing----------------------------------------------------------------------------------------\n",
    "\n",
    "if not os.path.exists(\"model.bin\"):\n",
    "    logging.info(\"Missing model, downloading\")\n",
    "    url = 'https://drive.google.com/uc?id=1uyIYjcPRg6TwIrLpa_p9bmCALtAax79F'\n",
    "    output = 'model.bin'\n",
    "    gdown.download(url, output, quiet=False)\n",
    "    logging.info(\"Model downloaded\")\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# DEFINE MODEl----------------------------------------------------------------------------------------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = get_model_definition()\n",
    "model.load_state_dict(torch.load(\"model.bin\"))\n",
    "\n",
    "IMAGE_SIZE = 512\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "my_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMG_MEAN, IMG_STD)\n",
    "])\n",
    "model = model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# CREATE AND DIFINE BUFFE-----------------------------------------------------------------------------------------------\n",
    "class Buffer(UserDict):\n",
    "    def __init__(self, max_size=10, *args, **kwargs):\n",
    "        self.max_size = max_size\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        if len(self) >= self.max_size:\n",
    "            oldest_key = next(iter(self))\n",
    "            del self[oldest_key]\n",
    "        super().__setitem__(key, value)\n",
    "\n",
    "\n",
    "buffer = Buffer(1000)\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"}\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"Image scorer backend.\")\n",
    "    with gr.Tab(\"I am here for api only, pls don't touch me\", visible=True):\n",
    "        # this is for image adding for database\n",
    "        img_input = gr.Textbox()\n",
    "        score_input = gr.Textbox()\n",
    "        button = gr.Button('Click me!')\n",
    "\n",
    "\n",
    "        def add_image(inp, score=None):\n",
    "            logging.info(f\"Got image with src {inp} and score {score}\")\n",
    "            conn = sqlite3.connect(os.path.join(\"flagged\", \"data.db\"))\n",
    "            c = conn.cursor()\n",
    "            c.execute(\"SELECT COUNT(*) FROM images\")\n",
    "\n",
    "            # Fetch the result of the query\n",
    "            row_count = c.fetchone()[0]\n",
    "\n",
    "            req = requests.get(inp, headers=headers)\n",
    "            img = Image.open(BytesIO(req.content))\n",
    "            img.save(os.path.join(\"flagged\", str(row_count) + \".png\"))\n",
    "            c.execute(\"INSERT INTO images (image_path, rating) VALUES (?, ?)\",\n",
    "                      (os.path.join(\"flagged\", str(row_count) + \".png\"), score))\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            logging.info(\"Image added\")\n",
    "            return \"readed\"\n",
    "\n",
    "\n",
    "        button.click(add_image, inputs=[img_input, score_input])\n",
    "\n",
    "        # this is for connection test\n",
    "        txt_output = gr.Textbox()\n",
    "        button = gr.Button('Connection test')\n",
    "\n",
    "\n",
    "        def return_ok():\n",
    "            logging.info(\"Connected\")\n",
    "            return \"connected\"\n",
    "\n",
    "\n",
    "        button.click(return_ok, outputs=txt_output)\n",
    "\n",
    "        # this is for model predict\n",
    "        img_input_predict = gr.Textbox()\n",
    "        score_output = gr.Textbox()\n",
    "        button = gr.Button('Predict')\n",
    "\n",
    "\n",
    "        def predict(inp):\n",
    "            if not str(inp):\n",
    "                logging.info(\"Got empty string, returning -1\")\n",
    "                return \"-1\"\n",
    "            if inp in buffer:\n",
    "                logging.info(f\"Using buffer, returned {buffer[inp]}\")\n",
    "                return buffer[inp]\n",
    "            try:\n",
    "                logging.info(f\"Got: {inp}\")\n",
    "                if str(inp).find(\"http\") != -1:\n",
    "                    logging.info(\"Requesting image\")\n",
    "                    req = requests.get(inp, headers=headers)\n",
    "                    logging.info(\"Got image\")\n",
    "                    img = Image.open(BytesIO(req.content)).convert('RGB')\n",
    "                if str(inp).find(\"base64\") != -1:\n",
    "                    logging.info(\"Got base64, decoding\")\n",
    "                    image_bytes = base64.b64decode(inp.split(',')[1])\n",
    "                    img = Image.open(BytesIO(image_bytes)).convert('RGB')\n",
    "                logging.info(\"Transforming image\")\n",
    "                img = my_transforms(img).to(device).unsqueeze(0)\n",
    "                logging.info(\"Predicting\")\n",
    "                ans = str(torch.argmax(model(img).sigmoid()).item() + 1)\n",
    "                logging.info(f\"Responsed with: {ans}\")\n",
    "                buffer[inp] = ans\n",
    "                torch.cuda.empty_cache()\n",
    "                return ans\n",
    "            except Exception:\n",
    "                logging.error(\"Error: \" + str(Exception), exc_info=True)\n",
    "                logging.error(f\"Response status was {req.status_code}\")\n",
    "                return \"-1\"\n",
    "\n",
    "\n",
    "        button.click(predict, inputs=img_input_predict, outputs=score_output)\n",
    "\n",
    "    with gr.Tab(\"Train tab\", visible=True):\n",
    "        button = gr.Button('Train model from ram')\n",
    "\n",
    "\n",
    "        def standart_eval_prep():\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            model.eval()\n",
    "            torch.cuda.empty_cache()\n",
    "            buffer.clear()\n",
    "\n",
    "\n",
    "        def train_with_flagged():\n",
    "            try:\n",
    "                train_model_from_ram_with_flagged(model, my_transforms, 15)\n",
    "                standart_eval_prep()\n",
    "            except:\n",
    "                standart_eval_prep()\n",
    "\n",
    "\n",
    "        button.click(train_with_flagged)\n",
    "\n",
    "        button = gr.Button('Train model from pretrained')\n",
    "\n",
    "\n",
    "        def train_from_pretrained():\n",
    "            try:\n",
    "                train_model_from_my_pretrained(my_transforms, 15)\n",
    "                standart_eval_prep()\n",
    "            except:\n",
    "                standart_eval_prep()\n",
    "\n",
    "\n",
    "        button.click(train_from_pretrained)\n",
    "\n",
    "app.queue(concurrency_count=1, max_size=60)\n",
    "app.launch(max_threads=1, share=True)\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
